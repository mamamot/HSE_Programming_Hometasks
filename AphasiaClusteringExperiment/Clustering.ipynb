{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кластеризация существительных по левому глагольному контексту\n",
    "Наша гипотеза состоит в том, что мы можем с помощью алгоритма кластеризации найти группы глаголов, которые ведут себя сходным образом. Для ее проверки мы исследуем существительные в подходящих контекстах: биграммы с переходными глаголами и существительными в соответствующих падежах (кроме именительного и предложного) и триграммы с переходными глаголами, предлогом и существительным.\n",
    "\n",
    "## Данные\n",
    "Данные взяты из НКРЯ (поиск по биграммам и триграммам).\n",
    "### Запрос:\n",
    "Обращение к данным происходит путем подстановки леммы в заранее сформированный запрос (см. reference.txt), извлечение данных - с помощью XPath.\n",
    "\n",
    "### Существительные:\n",
    "В качестве леммы в запросе к корпусу использовались первые 500 существительных из Частотного словаря русского языка, а также те слова, которые были получены в результате прошлого интерактива (если быть точным - их пересечение, порядка 900 слов).\n",
    "\n",
    "### Выход:\n",
    "Мы получаем данные в виде html-страницы с таблицей, строки которой имеют вид:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Формат строки в таблице (биграммы):\n",
    "<tr><td align=\"right\">27</td><td align=\"right\">15</td><td align=\"right\">13</td><td width=\"100%\"> <span class=\"b-wrd-expl g-em\" explain=\"%D0%BB%D1%8E%D0%B1%D0%B8%D0%BB%D0%B8%7C134%7C10%7C0%7C0%7C0%7C0%7C0\">любили</span> <span class=\"b-wrd-expl g-em\" explain=\"%D0%BE%D1%82%D1%86%D0%B0%7C1087%7C1%7C0%7C0%7C0%7C0%7C0\">отца</span> </td></tr>\n",
    "Формат строки в таблице (триграммы): \n",
    "<tr><td align=\"right\">4</td><td align=\"right\">45</td><td align=\"right\">36</td><td width=\"100%\"> <span class=\"b-wrd-expl g-em\" explain=\"%D0%B2%D0%B7%D0%B3%D0%BB%D1%8F%D0%BD%D1%83%D0%BB%7C377%7C60%7C0%7C0%7C0%7C0%7C0\">взглянул</span> <span class=\"b-wrd-expl g-em\" explain=\"%D0%BD%D0%B0%7C18%7C1%7C0%7C0%7C0%7C0%7C0\">на</span> <span class=\"b-wrd-expl g-em\" explain=\"%D0%BE%D1%82%D1%86%D0%B0%7C691%7C10%7C0%7C0%7C0%7C0%7C0\">отца</span> </td></tr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "import urllib.parse\n",
    "import pymorphy2\n",
    "import json\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "BIGRAM_LINK = \"http://search.ruscorpora.ru/search.xml?env=sas1_2&mycorp=&mysent=&mysize=&mysentsize=\" \\\n",
    "              \"&dpp=100&spp=100&spd=100&text=lexgramm&mode=ngrams_2_lexgr&sort=gr_freq&lang=ru&nodia=1\" \\\n",
    "              \"&parent1=0&level1=0&lex1=&gramm1=V%2Ctran&flags1=&parent2=0&level2=0&min2=1&max2=1&lex2={0}\" \\\n",
    "              \"&gramm2=%28gen%7Cgen2%7Cdat%7Cacc%7Cacc2%7Cins%29&flags2=\"\n",
    "TRIGRAM_LINK = \"http://search.ruscorpora.ru/search.xml?env=sas1_2&mycorp=&mysent=&mysize=&mysentsize=\" \\\n",
    "               \"&dpp=100&spp=100&spd=100&text=lexgramm&mode=ngrams_3_lexgr&sort=gr_freq&lang=ru&nodia=1\" \\\n",
    "               \"&parent1=0&level1=0&lex1=&gramm1=V&flags1=&parent2=0&level2=0&min2=1&max2=1&lex2=&gramm2=\" \\\n",
    "               \"PR&flags2=&parent3=0&level3=0&min3=1&max3=1&lex3={0}&gramm3=&flags3=\"\n",
    "\n",
    "agent_name = \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36\"\n",
    "            \n",
    "            \n",
    "# загрузка страниц\n",
    "def load_page(url, encoding=\"cp1251\"):\n",
    "    \"\"\"\n",
    "    Простая функция для загрузки страницы с сайта\n",
    "\n",
    "    :param url: URI of the page\n",
    "    :param encoding: page encoding\n",
    "    :return: tuple: a boolean showing success, content of the page (or error message), and http code if available (or 0)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        req = urllib.request.Request(urllib.parse.quote(url, safe=\":/&=?%\"), headers={'User-Agent': agent_name})\n",
    "        with urllib.request.urlopen(req) as r:\n",
    "            code = r.getcode()\n",
    "            page = r.read().decode(encoding)\n",
    "            loaded = True\n",
    "    except urllib.error.HTTPError as e:\n",
    "        page = e.reason\n",
    "        code = e.code\n",
    "        loaded = False\n",
    "    except urllib.error.URLError as e:\n",
    "        page = e.reason\n",
    "        code = 0\n",
    "        loaded = False\n",
    "    except Exception as e:\n",
    "        page = str(e)\n",
    "        code = 0\n",
    "        loaded = False\n",
    "    return loaded, page, code\n",
    "\n",
    "def load_words():\n",
    "    \"\"\"\n",
    "    Загрузка списка слов\n",
    "    \"\"\"\n",
    "    with open(\"w1.txt\", \"r\") as f:\n",
    "        txt = f.read()\n",
    "        words1 = txt.split(\"\\n\")\n",
    "        words1 = [w.strip().lower() for w in words1]\n",
    "    with open(\"w2.txt\", \"r\") as f:\n",
    "        txt = f.read()\n",
    "        words2 = txt.split(\"\\n\")\n",
    "        words2 = [w.strip().lower() for w in words2]\n",
    "    words = set(words1 + words2)\n",
    "    return words\n",
    "\n",
    "def create_link(word, is_trigram=False):\n",
    "    \"\"\"\n",
    "    Создает ссылки на страницы в соответствии с необходимым запросом\n",
    "    \"\"\"\n",
    "    if is_trigram:\n",
    "        return TRIGRAM_LINK.format(word)\n",
    "    else:\n",
    "        return BIGRAM_LINK.format(word)\n",
    "\n",
    "def lemma(token, morph):\n",
    "    \"\"\"\n",
    "    Получаем начальную форму и заодно ищем наиболее вероятный глагольный разбор токена.\n",
    "    Если глагольного разбора нет - возвращаем False.\n",
    "    \"\"\"\n",
    "    parse = morph.parse(token)\n",
    "    for p in parse:\n",
    "        if 'VERB' in p.tag:\n",
    "            return True, p.normal_form\n",
    "    return False, \"\"\n",
    "\n",
    "def extract_words_freqs(bi_page, tri_page):\n",
    "    \"\"\"\n",
    "    Извлекает из текста страницы глаголы/глаголы с предлогами и возвращает в виде словаря, где глаголы - ключи, частоты - \n",
    "    значения.\n",
    "    \"\"\"\n",
    "    output_dict = dict()\n",
    "    bi_tree = lxml.html.fromstring(bi_page)\n",
    "    # обходим таблицу на странице по строкам\n",
    "    for tr in bi_tree.iter('tr'):\n",
    "        # прямо в ячейках живут цифры (номер пп. и частотность)\n",
    "        td_text = tr.xpath(\".//td/text()\")\n",
    "        if not td_text:\n",
    "            continue\n",
    "        # в тегах span живут слова\n",
    "        span_text = tr.xpath(\".//td/span/text()\")\n",
    "        freq = int(td_text[1])\n",
    "        token = span_text[0]\n",
    "        is_verb, word = lemma(token, morph)\n",
    "        if is_verb:\n",
    "            if word in list(output_dict.keys()):\n",
    "                output_dict[word] = output_dict[word] + freq\n",
    "            else:\n",
    "                output_dict[word] = freq\n",
    "    tri_tree = lxml.html.fromstring(tri_page)\n",
    "    # переходим к триграммам\n",
    "    for tr in tri_tree.iter('tr'):\n",
    "        td_text = tr.xpath(\".//td/text()\")\n",
    "        if not td_text:\n",
    "            continue\n",
    "        # в тегах span живут слова\n",
    "        span_text = tr.xpath(\".//td/span/text()\")\n",
    "        freq = int(td_text[1])\n",
    "        token = span_text[0]\n",
    "        is_verb, word = lemma(token, morph)\n",
    "        prep_phrase = word + \" \" + span_text[1]\n",
    "        if is_verb:\n",
    "            if prep_phrase in list(output_dict.keys()):\n",
    "                output_dict[prep_phrase] = output_dict[prep_phrase] + freq\n",
    "            else:\n",
    "                output_dict[prep_phrase] = freq\n",
    "    return output_dict\n",
    "\n",
    "def loader(words):\n",
    "    \"\"\"\n",
    "    Составляем конечный словарь\n",
    "    \"\"\"\n",
    "    output_dict = dict()\n",
    "    counter = 1\n",
    "    for word in words:\n",
    "        print(\"Dumping data for {0}.\".format(word))\n",
    "        bi_loaded, bi_page, code = load_page(create_link(word, False))\n",
    "        tri_loaded, tri_page, code = load_page(create_link(word, True))\n",
    "        if bi_loaded and tri_loaded:\n",
    "            output_dict[word] = extract_words_freqs(bi_page, tri_page)\n",
    "            print(\"[{0}] Completed.\".format(str(counter)))\n",
    "            counter += 1\n",
    "    return output_dict\n",
    "\n",
    "def dumper():\n",
    "    \"\"\"\n",
    "    Запускаем процесс загрузки биграммов-триграммов и сохраняем результаты в json\n",
    "    \"\"\"\n",
    "    print(\"Starting the job\")\n",
    "    words = list(load_words())\n",
    "    print(\"Wordlist is loaded: {0} entries\".format(str(len(words))))\n",
    "    loaded = loader(words)\n",
    "    with open(\"out.json\", \"w\") as w:\n",
    "        json.dump(loaded, w)\n",
    "    return loaded\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Результат\n",
    "Мы имеем файл out.json, в котором сериализован словарь с данными. Данные представлены в виде словаря, ключами являются существительные, а значениями - еще один словарь: ключи - глаголы или биграммы глагол + предлог, а значения - количество их вхождений в корпус. \n",
    "### Предобработка данных\n",
    "Теперь необходимо преобразовать эти данные в более удобный для обработки вид. Представим каждое существительное как вектор в пространстве глагольных униграмм и биграмм, значениями каждой координаты будет количество вхождений в корпус."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>включать в</th>\n",
       "      <th>заявить</th>\n",
       "      <th>означать</th>\n",
       "      <th>видеть</th>\n",
       "      <th>выйти на</th>\n",
       "      <th>говорить о</th>\n",
       "      <th>думать о</th>\n",
       "      <th>полагать</th>\n",
       "      <th>объявить</th>\n",
       "      <th>быть</th>\n",
       "      <th>...</th>\n",
       "      <th>сдвинуться с</th>\n",
       "      <th>воротиться с</th>\n",
       "      <th>повести на</th>\n",
       "      <th>повелеть на</th>\n",
       "      <th>простудиться на</th>\n",
       "      <th>перемежаться с</th>\n",
       "      <th>манить на</th>\n",
       "      <th>располагать к</th>\n",
       "      <th>водить на</th>\n",
       "      <th>выпускаться на</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>853.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>853.000000</td>\n",
       "      <td>853.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.248535</td>\n",
       "      <td>6.062134</td>\n",
       "      <td>3.433763</td>\n",
       "      <td>12.811254</td>\n",
       "      <td>6.559203</td>\n",
       "      <td>4.434936</td>\n",
       "      <td>2.364596</td>\n",
       "      <td>2.473623</td>\n",
       "      <td>3.681125</td>\n",
       "      <td>42.162954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162954</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.008206</td>\n",
       "      <td>0.002345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>36.293912</td>\n",
       "      <td>171.095043</td>\n",
       "      <td>89.116316</td>\n",
       "      <td>228.061479</td>\n",
       "      <td>79.907166</td>\n",
       "      <td>68.368630</td>\n",
       "      <td>45.647501</td>\n",
       "      <td>70.056539</td>\n",
       "      <td>88.182198</td>\n",
       "      <td>229.973244</td>\n",
       "      <td>...</td>\n",
       "      <td>4.759269</td>\n",
       "      <td>0.136957</td>\n",
       "      <td>0.068479</td>\n",
       "      <td>0.068479</td>\n",
       "      <td>0.068479</td>\n",
       "      <td>0.068479</td>\n",
       "      <td>0.068479</td>\n",
       "      <td>0.068479</td>\n",
       "      <td>0.239675</td>\n",
       "      <td>0.068479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1060.000000</td>\n",
       "      <td>4997.000000</td>\n",
       "      <td>2602.000000</td>\n",
       "      <td>6643.000000</td>\n",
       "      <td>1982.000000</td>\n",
       "      <td>1966.000000</td>\n",
       "      <td>1318.000000</td>\n",
       "      <td>2046.000000</td>\n",
       "      <td>2561.000000</td>\n",
       "      <td>6205.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 9407 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        включать в      заявить     означать       видеть     выйти на  \\\n",
       "count   853.000000   853.000000   853.000000   853.000000   853.000000   \n",
       "mean      1.248535     6.062134     3.433763    12.811254     6.559203   \n",
       "std      36.293912   171.095043    89.116316   228.061479    79.907166   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     2.000000     0.000000   \n",
       "max    1060.000000  4997.000000  2602.000000  6643.000000  1982.000000   \n",
       "\n",
       "        говорить о     думать о     полагать     объявить         быть  \\\n",
       "count   853.000000   853.000000   853.000000   853.000000   853.000000   \n",
       "mean      4.434936     2.364596     2.473623     3.681125    42.162954   \n",
       "std      68.368630    45.647501    70.056539    88.182198   229.973244   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     6.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000    26.000000   \n",
       "max    1966.000000  1318.000000  2046.000000  2561.000000  6205.000000   \n",
       "\n",
       "            ...        сдвинуться с  воротиться с  повести на  повелеть на  \\\n",
       "count       ...          853.000000    853.000000  853.000000   853.000000   \n",
       "mean        ...            0.162954      0.004689    0.002345     0.002345   \n",
       "std         ...            4.759269      0.136957    0.068479     0.068479   \n",
       "min         ...            0.000000      0.000000    0.000000     0.000000   \n",
       "25%         ...            0.000000      0.000000    0.000000     0.000000   \n",
       "50%         ...            0.000000      0.000000    0.000000     0.000000   \n",
       "75%         ...            0.000000      0.000000    0.000000     0.000000   \n",
       "max         ...          139.000000      4.000000    2.000000     2.000000   \n",
       "\n",
       "       простудиться на  перемежаться с   манить на  располагать к   водить на  \\\n",
       "count       853.000000      853.000000  853.000000     853.000000  853.000000   \n",
       "mean          0.002345        0.002345    0.002345       0.002345    0.008206   \n",
       "std           0.068479        0.068479    0.068479       0.068479    0.239675   \n",
       "min           0.000000        0.000000    0.000000       0.000000    0.000000   \n",
       "25%           0.000000        0.000000    0.000000       0.000000    0.000000   \n",
       "50%           0.000000        0.000000    0.000000       0.000000    0.000000   \n",
       "75%           0.000000        0.000000    0.000000       0.000000    0.000000   \n",
       "max           2.000000        2.000000    2.000000       2.000000    7.000000   \n",
       "\n",
       "       выпускаться на  \n",
       "count      853.000000  \n",
       "mean         0.002345  \n",
       "std          0.068479  \n",
       "min          0.000000  \n",
       "25%          0.000000  \n",
       "50%          0.000000  \n",
       "75%          0.000000  \n",
       "max          2.000000  \n",
       "\n",
       "[8 rows x 9407 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Загружаем json\n",
    "with open(\"out.json\", \"r\") as f:\n",
    "    verb_dict = json.load(f)\n",
    "\n",
    "# Преобразовываем словарь в датафрейм\n",
    "verb_data = pd.DataFrame.from_dict(verb_dict, orient=\"index\", dtype=int)\n",
    "\n",
    "# Избавляемся от na-значений\n",
    "verb_data = verb_data.fillna(0)\n",
    "verb_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кластеризация\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
